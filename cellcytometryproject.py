# -*- coding: utf-8 -*-
"""CellCytometryProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZkNxIDokSJagByTHhFtRnJLFnmHAmS1o
"""



from google.colab import drive

drive.mount('/content/files')

import pandas

dataframe = pandas.read_table('/content/files/MyDrive/flow-cytometry-40k.txt.gz',
                              sep = ' ',
                              header = None)

dataframe

COLUMN_TO_DROP = 0
COLUMN_AXIS = 1

dataframe = dataframe.drop([COLUMN_TO_DROP],
              axis = COLUMN_AXIS)

dataframe

dataframe.columns = ["FITC-CD4","PE-CD8", "ECD-CD19", "PC5-CD45", "PC7-CD3"]

dataframe

dataframe_copy = dataframe.copy()

ROW_AXIS = 0

dataframe_copy.dropna(axis = ROW_AXIS,
                      inplace = True)

dataframe_copy

dataframe_copy = dataframe.copy()

average = dataframe_copy['FITC-CD4'].mean()

average

dataframe_copy.fillna(average,
                      inplace = True)

dataframe.hist(bins = 50, figsize = (15,10))

dataframe.describe()

dataframe = dataframe[dataframe['FITC-CD4'] < 20]

dataframe.hist(bins=50, figsize=(15,10))

dataframe = dataframe[dataframe['PC7-CD3'] < 250]
dataframe

dataframe.hist(bins=50, figsize=(15,10))

dataframe = dataframe[dataframe['PC5-CD45'] < 400]

dataframe.hist(bins=50, figsize=(15,10))

dataframe = dataframe[dataframe['ECD-CD19'] < 50]
dataframe

dataframe.hist(bins=50, figsize=(15,10))

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
dataframe_standardized = scaler.fit_transform(dataframe)

dataframe_standardized

from sklearn.preprocessing import MinMaxScaler

normalization = MinMaxScaler()

dataframe_normalized = normalization.fit_transform(dataframe)

dataframe_normalized

average_dataframe = dataframe.describe().loc["mean"].values
average_dataframe

standardized_averages = []
NUMBER_OF_FEATURES = 5

for feature in range(NUMBER_OF_FEATURES):
  standardized_averages.append(dataframe_standardized[:, feature].mean())

standardized_averages

normalized_averages = []

for feature in range (NUMBER_OF_FEATURES):
  normalized_averages.append(dataframe_normalized[:, feature].mean())

normalized_averages

from sklearn.decomposition import PCA

NUMBER_OF_DIMENSIONS = 2
pca = PCA(n_components = NUMBER_OF_DIMENSIONS)

scaler = StandardScaler()
normalized_data = scaler.fit_transform(dataframe)

data_reduced = pca.fit_transform(normalized_data)
data_reduced

info_retained = pca.explained_variance_ratio_

info_retained

import numpy

numpy.sum(info_retained)

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
MINIMUM_CLUSTERS = 2
MAXIMIMCLUSTERS = 15
ITERATIONVALUE = 1

distortions = []
silhouette_scores = []

for cluster in range (MINIMUM_CLUSTERS, MAXIMIMCLUSTERS, ITERATIONVALUE):
  model = KMeans(n_clusters = cluster,
                 init = "k-means++",
                 n_init = 100,
                 max_iter = 100,
                 random_state = 0)
  model.fit(normalized_data)
  distortions.append(model.inertia_)
  silhouette_scores.append(silhouette_score(normalized_data,
                                            model.labels_,
                                            metric = "euclidean"))

import matplotlib.pyplot as pyplot

pyplot.rcParams["figure.figsize"] = (15,10)

pyplot.plot(range(MINIMUM_CLUSTERS,
                  MAXIMIMCLUSTERS,
                  ITERATIONVALUE),
            distortions,
            marker = 'o')

pyplot.plot(range(MINIMUM_CLUSTERS,
                  MAXIMIMCLUSTERS,
                  ITERATIONVALUE),
            silhouette_scores,
            marker = 'o')

optimal_clusters = 4

model = KMeans(n_clusters = optimal_clusters,
               init = "k-means++",
               n_init = 10,
               max_iter = 100,
               random_state = 0)

model.fit(normalized_data)

clusters = model.labels_

dataframe.info()

dataframe["Cluster"] = clusters
dataframe

import seaborn
data_reduced = pandas.DataFrame(data_reduced,
                                columns = ["Principal Component 1",
                                "Principal Component 2"])

data_reduced["Cluster"] = clusters

seaborn.pairplot(x_vars = "Principal Component 1",
                 y_vars = "Principal Component 2",
                 data = data_reduced,
                 hue = "Cluster",
                 size = 10,
                 plot_kws = dict(alpha=0.5, s = 30))

